{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d988d1c-d2d9-4025-9287-f79e3d2ba88a",
   "metadata": {},
   "source": [
    "# SA2 Growth Rate Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dce56-8d50-43b8-8aea-f58ddd49363a",
   "metadata": {},
   "source": [
    "When making predictions for the SA2 region, we have two issues that need to be addressed\n",
    "1. What algorithm to use to predict the growth rate of SA2\n",
    "2. How to proceed with the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604d947-41ae-4dbb-a495-e0c8a6185192",
   "metadata": {},
   "source": [
    "## What algorithm to use to predict the growth rate of SA2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895eadb-1e9d-4659-bd96-97e5aab36ede",
   "metadata": {},
   "source": [
    "In the beginning, we chose lstm or rnn as our model, Through our analysis we found that lstm is more suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4651a-3db8-4ce4-b13e-e7b21f1625db",
   "metadata": {},
   "source": [
    "LSTM networks are an extension of recurrent neural networks (RNNs) mainly introduced to handle situations where RNNs fail. Talking about RNN, it is a network that works on the present input by taking into consideration the previous output (feedback) and storing in its memory for a short period of time (short-term memory). Out of its various applications, the most popular ones are in the fields of speech processing, non-Markovian control, and music composition. Nevertheless, there are drawbacks to RNNs. First, it fails to store information for a longer period of time. At times, a reference to certain information stored quite a long time ago is required to predict the current output. But RNNs are absolutely incapable of handling such “long-term dependencies”. Second, there is no finer control over which part of the context needs to be carried forward and how much of the past needs to be ‘forgotten’. Other issues with RNNs are exploding and vanishing gradients (explained later) which occur during the training process of a network through backtracking. Thus, Long Short-Term Memory (LSTM) was brought into the picture. It has been so designed that the vanishing gradient problem is almost completely removed, while the training model is left unaltered. Long time lags in certain problems are bridged using LSTMs where they also handle noise, distributed representations, and continuous values. With LSTMs, there is no need to keep a finite number of states from beforehand as required in the hidden Markov model (HMM). LSTMs provide us with a large range of parameters such as learning rates, and input and output biases. Hence, no need for fine adjustments. The complexity to update each weight is reduced to O(1) with LSTMs, similar to that of Back Propagation Through Time (BPTT), which is an advantage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cb3c8-6d32-41f8-bcf3-6264536a93ea",
   "metadata": {},
   "source": [
    "Since LSTM handles time series tasks better than CNN, in this section we use LSTM regions to predict growth rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df09868-76c4-4e33-adf8-20d3fa3b63b2",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58f23a-db7c-4a52-bafd-0e4c194bb9de",
   "metadata": {},
   "source": [
    "## How to proceed with the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b75f5-72a6-4453-9972-34e5e920f3b7",
   "metadata": {},
   "source": [
    "After determining the algorithm，Since pairs require predictions for each SA2 region, this chapter is roughly divided into two parts,\n",
    "- The first part uses a certain SA2 as an example to make a prediction\n",
    "- The second part is to sort all SA2 after prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0a9ac-97e0-4c62-9abe-a1d42c0a6679",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/analysis_part.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10059433-3453-40a8-b1f6-134859e784a7",
   "metadata": {},
   "source": [
    "### Single SA2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c378db-7923-4ab3-b765-6ee2b956a74d",
   "metadata": {},
   "source": [
    "In this section, Let's take 201011001 this SA2 as an example, we expand on the following four parts\n",
    "1. Load Dataset And Show Base Info\n",
    "2. Data visualization\n",
    "3. Feature Engineering\n",
    "4. Model Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30bf71-841f-4153-a4b2-4681bd7f3d33",
   "metadata": {},
   "source": [
    "#### Load Dataset And Show Base Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5e839-841c-479a-87cc-cf9e37d086e2",
   "metadata": {},
   "source": [
    "First, we have a basic understanding of the data by reading historical data, through statistical values such as variance, null values, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5a5e6-de1d-4f11-89f0-ccd6dc90d0af",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/base_info.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e07f8-d8df-4062-a32e-db7e57158e6a",
   "metadata": {},
   "source": [
    "#### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bdee2-4d0b-41bb-9550-edb77fdf3d0a",
   "metadata": {},
   "source": [
    "Then, we analysized the relationship between each feature and the label, which is roughly the trend of fluctuations within a certain range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03689ca-e1f3-482a-ab6a-384443f39e8c",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bae1a-48f0-43be-b133-48821c452248",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03383ef9-26f2-4b8a-942a-ebb46eb481c1",
   "metadata": {},
   "source": [
    "There are several main difficulties in predicting the future:\n",
    "- How to get future features\n",
    "- How to predict house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e979b-9400-4e45-a9f9-6f02f393b569",
   "metadata": {},
   "source": [
    "- How to get future features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835ce5d-146d-478d-bd0c-b59f2526282c",
   "metadata": {},
   "source": [
    "Because our data is very time-related, we explored the AR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4999a0-5023-4869-9410-38995154ac9c",
   "metadata": {},
   "source": [
    "Autoregressive (AR) modeling is one of the techniques used for time-series analysis. An autoregressive model is a time-series model that describes how a particular variable’s past values influence its current value. In other words, an AR model attempts to predict the next value in a series by incorporating the most recent past values and using them as input data. Autoregressive models are based on the idea that past events can help us predict future events. For example, if we know that the stock market has been going up for the past few days, we might expect it to continue going up in the future. Or, if we know that there has been a lot of rain lately, we might expect more rain in the future.\n",
    "\n",
    "Autoregressive modeling is training a regression model on the value of the response variable itself. Autoregressive is made of the word, Auto and Regressive which represents the linear regression on itself (auto). In the context of time-series forecasting, autoregressive modeling will mean creating the model where the response variable Y will depend upon the previous values of Y at a pre-determined constant time lag. The time lag can be daily (or 2, 3, 4… days), weekly, monthly, etc. A great way to explain this would be that if I were predicting what the stock price will be at 12 pm tomorrow based on the stock price today, then my model might have an auto part where each day affects the next day’s value just like regular linear regression does but also has regressive features which mean there are different factors influencing changes over shorter spans such as days rather than weeks. AR models can be used to model anything that has some degree of autocorrelation which means that there is a correlation between observations at adjacent time steps. The most common use case for this type of modeling is with stock market prices where the price today (t) is highly correlated with the price one day ago (t-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee102c-f72a-4d48-b9f8-ceb4286213b5",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/autoregressive-model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bbeed-c9c0-453e-9413-9d4309da6d8f",
   "metadata": {},
   "source": [
    "Since our data is divided by quarters, we set the order to 4, i.e. AR(4)\n",
    "\n",
    "This is the change in population predicted by our AR model over time\n",
    "\n",
    "We use the same method to predict the other 6 characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4382a-8af9-4617-b462-901d14b8d71a",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/population.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db06a8c-ad33-4642-83fc-d09e1647f2c1",
   "metadata": {},
   "source": [
    "The **red part** is our forecast value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c30953-b6ee-44b8-a927-0e2716ef2e94",
   "metadata": {},
   "source": [
    "#### Feature Engineering and Model Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa329c46-9cff-46cd-a5ea-5df0f72e80af",
   "metadata": {},
   "source": [
    "In this section, we first divide the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5788-e40c-415d-a9bf-e0846b031a7d",
   "metadata": {},
   "source": [
    "And, Construct batch data methods(create_batch_dataset) to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36609d8-b641-4f21-a045-e35ca08fe8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_dataset(X, y, train=True, buffer_size=1000, batch_size=128):\n",
    "    batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "    if train:\n",
    "        return batch_data.cache().shuffle(buffer_size).batch(batch_size)\n",
    "    else:\n",
    "        return batch_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192eb8b-6cbe-4e45-a7f7-1679919ce846",
   "metadata": {},
   "source": [
    "Then I created the model with the help of tensorflow.keras，The model structure is as follows："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804c9df-4500-459c-bc7e-cf0287c6fbfe",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f800d-0c7b-49e6-94e3-1eef1cd00f3e",
   "metadata": {},
   "source": [
    "With historical and future data, then we can use LSTM for training and prediction\n",
    "The model we built is shown in the figure\n",
    "Two layers of LSTM are used, and finally the Dense layer is used to output prediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af81699b-488d-4f8b-ac39-10762f48b4ec",
   "metadata": {},
   "source": [
    "here is some output during training\n",
    "- model structure: `models/model.png`\n",
    "- model training logs: `models/logs`\n",
    "- the best model:`models/best_model.hdf5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01084be5-a3e9-430c-a2a3-7cc1a4fd8058",
   "metadata": {},
   "source": [
    "This is the model loss, We can see that the loss is really declining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9ad0c-bd96-41df-ad2d-785d41eec3c8",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ffe72-d761-4865-82f8-98fba6b2ea20",
   "metadata": {},
   "source": [
    "### ALL SA2 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0ed38-0a1f-4443-a31a-356bb0ada734",
   "metadata": {},
   "source": [
    "Based on the above analysis, we can give forecasts for the growth rate of all SA2 regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7afdc4-cd1b-4a87-b796-1556e8fadab4",
   "metadata": {},
   "source": [
    "![](../plots/sa2_predict/all_predict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feacbd5-4c5f-483b-b68e-be258b458d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
