{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final outputs:\n",
    "\n",
    "Digital boundary (AUS range, manually select VIC if needed)\n",
    "- ../data/raw/ABS/digitalBoundary/SA2_2021_AUST_GDA2020.shp\n",
    "\n",
    "SA2 code to district names\n",
    "- ../data/raw/ABS/SA2_TO_Name.csv\n",
    "- code(int), name(String)\n",
    "\n",
    "\n",
    "Estimated Resident Population (ERP) (2001 to 2021) (By SA2)\n",
    "- ../data/raw/ABS/ERP/ERP.csv\n",
    "- SA2 (int), year (int), population (int)\n",
    "- SA2: interger code marking each district, e.g. 206041117 for Carlton\n",
    "\n",
    "Household income (weekly) (exclude visitor/non-classifiable) (2021) (By SA2)\n",
    "- ../data/raw/ABS/Household_income/Household_income.csv\n",
    "- SA2 (int), year (int),  household_type (String), income_level (String), popultaion (int)\n",
    "\n",
    "Population projection (2017 - 2066) (VIC overall)\n",
    "- ../data/raw/ABS/Population/Population.csv\n",
    "- year (int), popultaion (int)\n",
    "\n",
    "School location\n",
    "- ../data/raw/ABS/School_location/School_location.csv\n",
    "- School Name (String), SA2 (int), Latitude (float), Longitude (float), School Type (String)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/05 20:32:55 WARN Utils: Your hostname, Bruce-PC resolves to a loopback address: 127.0.1.1; using 172.21.194.51 instead (on interface eth0)\n",
      "22/09/05 20:32:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/05 20:32:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import requests\n",
    "import math\n",
    "import zipfile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Assignment_2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "\n",
    "OUTPUT_DIR = \"../data/raw/ABS/\"\n",
    "\n",
    "headers = {\"accept\": \"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_direct(url, output_dir, file_name):\n",
    "    \"\"\"\n",
    "    use urlretrieve function to directly pull data from given url and save it \n",
    "        to path: {output_dir}{file_name}\n",
    "    url: the String url which needs to be pulled from\n",
    "    output_dir: the String output folder directory, automatically create if not exist\n",
    "    file_name: the String file name of the file needed to be pulled from\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        urlretrieve(url, f\"{output_dir}{file_name}\")\n",
    "        print(\n",
    "            f\"Request succeed: pulling from{url}\\nFile saved in: {output_dir}{file_name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"********\\nRequest failure: \")\n",
    "        print(e)\n",
    "        print(\"********\")\n",
    "\n",
    "\n",
    "def write_file(output_dir, file_name, content, mod=\"w\"):\n",
    "    \"\"\"\n",
    "    write given content to local file at: {output_dir}{file_name} with mode: {mod}\n",
    "    output_dir: the String output folder directory, automatically create if not exist\n",
    "    file_name: the String file name used to save file\n",
    "    content: expecting objects which can be written to file with open function\n",
    "    mod: String of writing mode code used in writing file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        with open(f\"{output_dir}{file_name}\", mod) as f:\n",
    "            f.write(content)\n",
    "    except Exception as e:\n",
    "        print(f\"****** Writing file failure: {output_dir}{file_name}\")\n",
    "        print(e)\n",
    "        print(\"******\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_match_list(\n",
    "    url,\n",
    "    output_dir,\n",
    "    file_name,\n",
    "    xpath=\".//structure:Code\",\n",
    "    name_space={\n",
    "        \"structure\": \"http://www.sdmx.org/resources/sdmxml/schemas/v2_1/structure\"\n",
    "    },\n",
    "):\n",
    "    \"\"\"\n",
    "    Used to download match list to {output_dir}{file_name} using given {url}\n",
    "    Using {xpath} and {name_space} when reading the pulled xml\n",
    "    url: the String url which needs to be pulled from\n",
    "    output_dir: the String output folder directory, \n",
    "        automatically create if not exist\n",
    "    file_name: the String file name used to save file\n",
    "    xpath: A String used to select data in xml\n",
    "    name_space: A String used to select data in xml\n",
    "    \"\"\"\n",
    "\n",
    "    # pull_direct(url, output_dir, f\"{file_name}.xml\")\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(f\"{output_dir}{file_name}.xml\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    print(f\"data saved: {output_dir}{file_name}.xml\")\n",
    "\n",
    "    # select data from xml\n",
    "    df = pd.read_xml(f\"{output_dir}{file_name}.xml\", xpath=xpath, namespaces=name_space)\n",
    "    df.to_csv(f\"{output_dir}{file_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SA2 to district name match tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeed: pulling fromhttps://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/allocation-files/SA2_2021_AUST.xlsx\n",
      "File saved in: ../data/raw/ABS/SA2_TO_Name.xlsx\n"
     ]
    }
   ],
   "source": [
    "### Pull SA2 match table\n",
    "url = f\"https://www.abs.gov.au/statistics/standards/australian-statistical\\\n",
    "-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads\\\n",
    "/allocation-files/SA2_2021_AUST.xlsx\"\n",
    "file_name = \"SA2_TO_Name.xlsx\"\n",
    "pull_direct(url, OUTPUT_DIR, file_name)\n",
    "\n",
    "# Select victoria data then save\n",
    "vic_df = pd.read_excel(f\"{OUTPUT_DIR}{file_name}\")\n",
    "vic_df = vic_df.loc[vic_df[\"STATE_NAME_2021\"] == \"Victoria\"]\n",
    "vic_df = vic_df[[\"SA2_CODE_2021\", \"SA2_NAME_2021\"]].rename(\n",
    "    columns={\"SA2_CODE_2021\": \"code\", \"SA2_NAME_2021\": \"name\"}\n",
    ")\n",
    "vic_df.to_csv(f\"{OUTPUT_DIR}SA2_TO_Name.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SA2 shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeed: pulling fromhttps://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\n",
      "File saved in: ../data/raw/ABS/SA2_2021_AUST_SHP_GDA2020.zip\n"
     ]
    }
   ],
   "source": [
    "### pull shape file\n",
    "url = f\"https://www.abs.gov.au/statistics/standards/australian-statistical\\\n",
    "-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads\\\n",
    "/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "file_name = \"SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "pull_direct(url, OUTPUT_DIR, file_name)\n",
    "\n",
    "# unzip zip file\n",
    "with zipfile.ZipFile(f\"{OUTPUT_DIR}{file_name}\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(f\"{OUTPUT_DIR}digitalBoundary/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated Resident Population (ERP) (2001 to 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved: ../data/raw/ABS/ERP/ERP_match.xml\n"
     ]
    }
   ],
   "source": [
    "### Pull ERP data\n",
    "url = \"https://api.data.abs.gov.au/data/ABS,ABS_ANNUAL_ERP_ASGS2021,1.2.0/.\\\n",
    "SA2..A?startPeriod=2010&endPeriod=2021&dimensionAtObservation=AllDimensions\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}ERP/\", \"ERP_raw.csv\", response.text)\n",
    "\n",
    "### pull ERP match table\n",
    "match_url = \"https://api.data.abs.gov.au/datastructure/ABS/ABS_ANNUAL_ERP\\\n",
    "_ASGS2021/1.2.0?references=all\"\n",
    "match_output_dir = f\"{OUTPUT_DIR}ERP/\"\n",
    "match_file_name = \"ERP_match\"\n",
    "get_match_list(match_url, match_output_dir, match_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before selection:\n",
      "-RECORD 0------------------------------------------\n",
      " DATAFLOW     | ABS:ABS_ANNUAL_ERP_ASGS2021(1.2.0) \n",
      " MEASURE      | ERP                                \n",
      " REGION_TYPE  | SA2                                \n",
      " ASGS_2021    | 101021010                          \n",
      " FREQ         | A                                  \n",
      " TIME_PERIOD  | 2010                               \n",
      " OBS_VALUE    | 4813                               \n",
      " UNIT_MEASURE | PSNS                               \n",
      " OBS_STATUS   | null                               \n",
      " OBS_COMMENT  | null                               \n",
      "-RECORD 1------------------------------------------\n",
      " DATAFLOW     | ABS:ABS_ANNUAL_ERP_ASGS2021(1.2.0) \n",
      " MEASURE      | ERP                                \n",
      " REGION_TYPE  | SA2                                \n",
      " ASGS_2021    | 101021010                          \n",
      " FREQ         | A                                  \n",
      " TIME_PERIOD  | 2011                               \n",
      " OBS_VALUE    | 4951                               \n",
      " UNIT_MEASURE | PSNS                               \n",
      " OBS_STATUS   | null                               \n",
      " OBS_COMMENT  | null                               \n",
      "only showing top 2 rows\n",
      "\n",
      "After selection\n",
      "-RECORD 0---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2010      \n",
      " population | 8664      \n",
      "-RECORD 1---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2011      \n",
      " population | 8814      \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "erp_sdf = spark.read.csv(f\"{OUTPUT_DIR}ERP/ERP_raw.csv\", header=True)\n",
    "print(\"Before selection:\")\n",
    "erp_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# feature selection / rename / reset datatype\n",
    "erp_sdf = erp_sdf[[\"ASGS_2021\", \"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "erp_sdf = (\n",
    "    erp_sdf.withColumnRenamed(\"ASGS_2021\", \"SA2\")\n",
    "    .withColumn(\"SA2\", F.col(\"SA2\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"OBS_VALUE\", \"population\")\n",
    "    .withColumn(\"population\", F.col(\"population\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# Filter: victoria SA2\n",
    "vic_df = pd.read_csv(f\"{OUTPUT_DIR}SA2_TO_Name.csv\")\n",
    "vic_sa2 = vic_df[\"code\"].tolist()\n",
    "erp_sdf = erp_sdf.filter(F.col(\"SA2\").isin(vic_sa2))\n",
    "\n",
    "# save file\n",
    "print(\"After selection:\")\n",
    "erp_sdf.show(2, vertical=True, truncate=100)\n",
    "erp_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(f\"{OUTPUT_DIR}ERP/ERP.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Household income (weekly) (exclude visitor/non-classifiable) (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved: ../data/raw/ABS/Household_income/Household_income_match.xml\n"
     ]
    }
   ],
   "source": [
    "### pull household income data\n",
    "url = f\"https://api.data.abs.gov.au/data/ABS,C21_G33_SA2,1.0.0/...SA2.?\\\n",
    "startPeriod=2021&dimensionAtObservation=AllDimensions\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}Household_income/\", \"Household_income_raw.csv\",\n",
    "            response.text)\n",
    "\n",
    "### pull match data\n",
    "match_url = \"https://api.data.abs.gov.au/datastructure/ABS/C21_G33_SA2/1.\\\n",
    "0.0?references=all\"\n",
    "match_output_dir = f\"{OUTPUT_DIR}Household_income/\"\n",
    "match_file_name = \"Household_income_match\"\n",
    "get_match_list(match_url, match_output_dir, match_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before selection:\n",
      "-RECORD 0-----------------------------\n",
      " DATAFLOW    | ABS:C21_G33_SA2(1.0.0) \n",
      " HIND        | 7                      \n",
      " HHCD        | 1_2                    \n",
      " REGION      | 101021008              \n",
      " REGION_TYPE | SA2                    \n",
      " STATE       | 1                      \n",
      " TIME_PERIOD | 2021                   \n",
      " OBS_VALUE   | 94                     \n",
      "-RECORD 1-----------------------------\n",
      " DATAFLOW    | ABS:C21_G33_SA2(1.0.0) \n",
      " HIND        | 7                      \n",
      " HHCD        | _T                     \n",
      " REGION      | 101021611              \n",
      " REGION_TYPE | SA2                    \n",
      " STATE       | 1                      \n",
      " TIME_PERIOD | 2021                   \n",
      " OBS_VALUE   | 124                    \n",
      "only showing top 2 rows\n",
      "\n",
      "After selection:\n",
      "-RECORD 0---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "-RECORD 1---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "income_sdf = spark.read.csv(\n",
    "    f\"{OUTPUT_DIR}Household_income/Household_income_raw.csv\", header=True\n",
    ")\n",
    "print(\"Before selection:\")\n",
    "income_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# feature selection / rename / reset datatype\n",
    "income_sdf = income_sdf[[\"REGION\", \"HIND\", \"HHCD\", \"OBS_VALUE\", \"STATE\", \"TIME_PERIOD\"]]\n",
    "income_sdf = (\n",
    "    income_sdf.withColumnRenamed(\"REGION\", \"SA2\")\n",
    "    .withColumn(\"SA2\", F.col(\"SA2\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"OBS_VALUE\", \"popultaion\")\n",
    "    .withColumn(\"popultaion\", F.col(\"popultaion\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"STATE\", \"state\")\n",
    "    .withColumn(\"state\", F.col(\"state\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"HIND\", \"income_level\")\n",
    "    .withColumnRenamed(\"HHCD\", \"household_type\")\n",
    ")\n",
    "match_sdf = spark.read.csv(\n",
    "    f\"{OUTPUT_DIR}Household_income/Household_income_match.csv\", header=True\n",
    ")[[\"id\", \"Name\"]].withColumnRenamed(\"id\", \"code\")\n",
    "\n",
    "# Filter: victoria\n",
    "income_sdf = income_sdf.filter(F.col(\"state\") == 2)\n",
    "income_sdf = income_sdf[[\"SA2\", \"year\", \"household_type\", \"income_level\",\\\n",
    "                        \"popultaion\"]]\n",
    "\n",
    "\n",
    "# inner join\n",
    "match_sdf.createOrReplaceTempView(\"match\")\n",
    "income_sdf.createOrReplaceTempView(\"income_sdf\")\n",
    "matched_sdf = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT SA2, year, Name AS household_type, income_level, popultaion\n",
    "    FROM(\n",
    "        SELECT SA2, year, household_type, Name AS income_level, popultaion\n",
    "        FROM income_sdf\n",
    "        INNER JOIN match ON income_sdf.income_level = match.code) AS half\n",
    "    INNER JOIN match ON half.household_type = match.code\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# write filtered file\n",
    "print(\"After selection:\")\n",
    "matched_sdf.show(2, vertical=True, truncate=100)\n",
    "matched_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}Household_income/Household_income.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population projection (2017 - 2066)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved: ../data/raw/ABS/Population/Population_match.xml\n"
     ]
    }
   ],
   "source": [
    "### pull popultation projection data\n",
    "url = \"https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION_2012_2061,\\\n",
    "1.0.0/2.3.TT.1.1.1.1.A?startPeriod=2017&dimensionAtObservation=AllDimensions\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}Population/\", \"Population_raw.csv\", response.text)\n",
    "\n",
    "### pull match tabel\n",
    "match_url = \"https://api.data.abs.gov.au/datastructure/ABS/POP_PROJ_REGION_\\\n",
    "2012_2061/1.0.0?references=all\"\n",
    "match_output_dir = f\"{OUTPUT_DIR}Population/\"\n",
    "match_file_name = \"Population_match\"\n",
    "get_match_list(match_url, match_output_dir, match_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before selection:\n",
      "-RECORD 0--------------------------------------------\n",
      " DATAFLOW     | ABS:POP_PROJ_REGION_2012_2061(1.0.0) \n",
      " REGION       | 2                                    \n",
      " SEX_ABS      | 3                                    \n",
      " AGE          | TT                                   \n",
      " FERTILITY    | 1                                    \n",
      " MORTALITY    | 1                                    \n",
      " NOM          | 1                                    \n",
      " NIM          | 1                                    \n",
      " FREQUENCY    | A                                    \n",
      " TIME_PERIOD  | 2017                                 \n",
      " OBS_VALUE    | 6321648                              \n",
      " UNIT_MEASURE | PSNS                                 \n",
      " OBS_STATUS   | null                                 \n",
      " OBS_COMMENT  | null                                 \n",
      "-RECORD 1--------------------------------------------\n",
      " DATAFLOW     | ABS:POP_PROJ_REGION_2012_2061(1.0.0) \n",
      " REGION       | 2                                    \n",
      " SEX_ABS      | 3                                    \n",
      " AGE          | TT                                   \n",
      " FERTILITY    | 1                                    \n",
      " MORTALITY    | 1                                    \n",
      " NOM          | 1                                    \n",
      " NIM          | 1                                    \n",
      " FREQUENCY    | A                                    \n",
      " TIME_PERIOD  | 2018                                 \n",
      " OBS_VALUE    | 6471149                              \n",
      " UNIT_MEASURE | PSNS                                 \n",
      " OBS_STATUS   | null                                 \n",
      " OBS_COMMENT  | null                                 \n",
      "only showing top 2 rows\n",
      "\n",
      "After selection:\n",
      "-RECORD 0-------------\n",
      " year       | 2017    \n",
      " popultaion | 6321648 \n",
      "-RECORD 1-------------\n",
      " year       | 2018    \n",
      " popultaion | 6471149 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "population_sdf = spark.read.csv(\n",
    "    f\"{OUTPUT_DIR}Population/Population_raw.csv\", header=True\n",
    ")\n",
    "print(\"Before selection:\")\n",
    "population_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# feature selection / rename / reset datatype\n",
    "population_sdf = population_sdf[[\"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "population_sdf = (\n",
    "    population_sdf.withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"OBS_VALUE\", \"popultaion\")\n",
    "    .withColumn(\"popultaion\", F.col(\"popultaion\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# save modified file\n",
    "print(\"After selection:\")\n",
    "population_sdf.show(2, vertical=True, truncate=100)\n",
    "population_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}Population/Population.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "School location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull school location file\n",
    "url = \"https://www.acara.edu.au/docs/default-source/default-document-\\\n",
    "library/school-location-2021e23a2f404c94637ead88ff00003e0139.xlsx\\\n",
    "?sfvrsn=51ae4c07_0\"\n",
    "response = requests.get(url)\n",
    "write_file(f\"{OUTPUT_DIR}School_location/\", \"School_location_raw.xlsx\",\n",
    "            response.content, \"wb\")\n",
    "# pull_direct(url, OUTPUT_DIR, f\"School_location.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             School Name        SA2  Latitude  Longitude  \\\n",
      "241   Kurnai College - University Campus  205041094  -38.3094   146.4249   \n",
      "295         Learning Co-Operative School  209031212  -37.6294   145.2133   \n",
      "297                        Andale School  207011153  -37.8055   145.0360   \n",
      "298                 The Currajong School  208041195  -37.8760   145.0599   \n",
      "299  Mansfield Autism Statewide Services  204011057  -37.0608   146.0859   \n",
      "\n",
      "    School Type  \n",
      "241   Secondary  \n",
      "295     Primary  \n",
      "297    Combined  \n",
      "298    Combined  \n",
      "299    Combined  \n",
      "(2729, 5)\n"
     ]
    }
   ],
   "source": [
    "# feature selection / VIC filtering\n",
    "school_df = pd.read_excel(\n",
    "    f\"{OUTPUT_DIR}School_location/School_location_raw.xlsx\",\n",
    "    sheet_name=\"SchoolLocations 2021\",\n",
    ")[[\"School Name\", \"Statistical Area 2\", \"State\", \"Latitude\", \n",
    "    \"Longitude\", \"School Type\"]]\n",
    "school_df = school_df.loc[school_df[\"State\"] == \"VIC\"]\n",
    "school_df = school_df.rename(columns={\"Statistical Area 2\": \"SA2\"})\n",
    "school_df = school_df.drop(columns=\"State\")\n",
    "\n",
    "print(school_df.head())\n",
    "print(school_df.shape)\n",
    "\n",
    "# save filtered data\n",
    "school_df.to_csv(f\"{OUTPUT_DIR}School_location/School_location.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = \"../plots/geo/draft/\"\n",
    "\n",
    "# read shape file and make geometry readable\n",
    "shape_gdf = gpd.read_file(\"../data/raw/ABS/digitalBoundary/\\\n",
    "SA2_2021_AUST_GDA2020.shp\")\n",
    "shape_gdf = shape_gdf.loc[shape_gdf[\"STE_NAME21\"] == \"Victoria\"]\n",
    "shape_gdf[\"geometry\"] = shape_gdf[\"geometry\"].to_crs(\n",
    "    \" proj=longlat  ellps=WGS84  datum=WGS84  no_defs\"\n",
    ")\n",
    "\n",
    "# plto Choropleth map\n",
    "geoJSON = shape_gdf[[\"SA2_CODE21\", \"geometry\"]]\\\n",
    "    .drop_duplicates(\"SA2_CODE21\").to_json()\n",
    "base_map = folium.Map(location=[-37.79, 144.96],\n",
    "    tiles=\"Stamen Terrain\", zoom_start=7.3)\n",
    "base_map.add_child(folium.Choropleth(geo_data=geoJSON,\n",
    "                                    name=\"choropleth\"))\n",
    "\n",
    "# save plot\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "base_map.save(f\"{plot_dir}base_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line and run to view the map\n",
    "# base_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14281423cfd62cfe9e63b7bdf907d0748b184f9fa760eb066fe3be6cb6246e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
