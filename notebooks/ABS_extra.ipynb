{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 22:29:56 WARN Utils: Your hostname, Bruce-PC resolves to a loopback address: 127.0.1.1; using 172.21.207.100 instead (on interface eth0)\n",
      "22/09/08 22:29:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 22:29:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import math\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from itertools import compress\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Assignment_2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "\n",
    "OUTPUT_DIR = \"../data/raw/ABS/\"\n",
    "\n",
    "headers = {\"accept\": \"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_direct(url, output_dir, file_name):\n",
    "    \"\"\"\n",
    "    use urlretrieve function to directly pull data from given url and save it \n",
    "        to path: {output_dir}{file_name}\n",
    "    url: the String url which needs to be pulled from\n",
    "    output_dir: the String output folder directory, automatically create if not exist\n",
    "    file_name: the String file name of the file needed to be pulled from\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        urlretrieve(url, f\"{output_dir}{file_name}\")\n",
    "        print(\n",
    "            f\"Request succeed: pulling from{url}\\nFile saved in: {output_dir}{file_name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"********\\nRequest failure: \")\n",
    "        print(e)\n",
    "        print(\"********\")\n",
    "\n",
    "\n",
    "def write_file(output_dir, file_name, content, mod=\"w\"):\n",
    "    \"\"\"\n",
    "    write given content to local file at: {output_dir}{file_name} with mode: {mod}\n",
    "    output_dir: the String output folder directory, automatically create if not exist\n",
    "    file_name: the String file name used to save file\n",
    "    content: expecting objects which can be written to file with open function\n",
    "    mod: String of writing mode code used in writing file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        with open(f\"{output_dir}{file_name}\", mod) as f:\n",
    "            f.write(content)\n",
    "    except Exception as e:\n",
    "        print(f\"****** Writing file failure: {output_dir}{file_name}\")\n",
    "        print(e)\n",
    "        print(\"******\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_match_list(\n",
    "    url,\n",
    "    output_dir,\n",
    "    file_name,\n",
    "    xpath=\".//structure:Code\",\n",
    "    name_space={\n",
    "        \"structure\": \"http://www.sdmx.org/resources/sdmxml/schemas/v2_1/structure\"\n",
    "    },\n",
    "):\n",
    "    \"\"\"\n",
    "    Used to download match list to {output_dir}{file_name} using given {url}\n",
    "    Using {xpath} and {name_space} when reading the pulled xml\n",
    "    url: the String url which needs to be pulled from\n",
    "    output_dir: the String output folder directory, \n",
    "        automatically create if not exist\n",
    "    file_name: the String file name used to save file\n",
    "    xpath: A String used to select data in xml\n",
    "    name_space: A String used to select data in xml\n",
    "    \"\"\"\n",
    "\n",
    "    # pull_direct(url, output_dir, f\"{file_name}.xml\")\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(f\"{output_dir}{file_name}.xml\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    print(f\"data saved: {output_dir}{file_name}.xml\")\n",
    "\n",
    "    # select data from xml\n",
    "    df = pd.read_xml(f\"{output_dir}{file_name}.xml\", xpath=xpath, namespaces=name_space)\n",
    "    df.to_csv(f\"{output_dir}{file_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greater Capital City Statistical Areas (GCCSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeed: pulling fromhttps://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/allocation-files/GCCSA_2021_AUST.xlsx\n",
      "File saved in: ../data/raw/Prediction/GCCSA_TO_Name.xlsx\n"
     ]
    }
   ],
   "source": [
    "### Pull SA2 match table\n",
    "url = f\"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/allocation-files/GCCSA_2021_AUST.xlsx\"\n",
    "file_name = \"GCCSA_TO_Name.xlsx\"\n",
    "pull_direct(url, OUTPUT_DIR, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater Melbourne\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "vic_df = pd.read_excel(f\"{OUTPUT_DIR}GCCSA_TO_Name.xlsx\")\n",
    "\n",
    "# Select greater melbourne areas\n",
    "gmelb_code = vic_df.loc[vic_df[\"GCCSA_NAME_2021\"] == \"Greater Melbourne\"][\"GCCSA_NAME_2021\"].values.tolist()[0]\n",
    "\n",
    "print(gmelb_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residential Property Price Index (1/2011 - 12/2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Pull Price_index data\n",
    "url = \"https://api.data.abs.gov.au/data/ABS,RPPI,1.0.0/1.3.2GMEL.Q?startPeriod=2011-Q1&endPeriod=2021-Q4&dimensionAtObservation=AllDimensions\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}Price_index/\", \"Price_index_raw.csv\", response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before selection:\n",
      "-RECORD 0------------------------\n",
      " DATAFLOW      | ABS:RPPI(1.0.0) \n",
      " MEASURE       | 1               \n",
      " PROPERTY_TYPE | 3               \n",
      " REGION        | 2GMEL           \n",
      " FREQ          | Q               \n",
      " TIME_PERIOD   | 2011-Q1         \n",
      " OBS_VALUE     | 104.7           \n",
      " UNIT_MEASURE  | IN              \n",
      " OBS_STATUS    | null            \n",
      " OBS_COMMENT   | null            \n",
      "-RECORD 1------------------------\n",
      " DATAFLOW      | ABS:RPPI(1.0.0) \n",
      " MEASURE       | 1               \n",
      " PROPERTY_TYPE | 3               \n",
      " REGION        | 2GMEL           \n",
      " FREQ          | Q               \n",
      " TIME_PERIOD   | 2011-Q2         \n",
      " OBS_VALUE     | 103.5           \n",
      " UNIT_MEASURE  | IN              \n",
      " OBS_STATUS    | null            \n",
      " OBS_COMMENT   | null            \n",
      "only showing top 2 rows\n",
      "\n",
      "After selection:\n",
      "-RECORD 0-----------\n",
      " year        | 2011 \n",
      " price_index | 100  \n",
      "-RECORD 1-----------\n",
      " year        | 2012 \n",
      " price_index | 100  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "price_sdf = spark.read.csv(f\"{OUTPUT_DIR}Price_index/Price_index_raw.csv\", header=True)\n",
    "print(\"Before selection:\")\n",
    "price_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# feature selection / rename / reset datatype\n",
    "price_sdf = price_sdf[[\"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "price_sdf = (\n",
    "    price_sdf.withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "    .withColumnRenamed(\"OBS_VALUE\", \"price_index\")\n",
    "    .withColumn(\"price_index\", F.col(\"price_index\").cast(\"int\"))\n",
    ")\n",
    "price_sdf = price_sdf.filter(F.col(\"year\").contains(\"Q4\"))\n",
    "price_sdf = price_sdf.withColumn(\"year\", F.substring(\"year\", 1, 4).cast(\"int\"))\n",
    "\n",
    "# save file\n",
    "print(\"After selection:\")\n",
    "price_sdf.show(2, vertical=True, truncate=100)\n",
    "price_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(f\"{OUTPUT_DIR}Price_index/Price_index.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Pull Price_index data\n",
    "url = \"https://www.rba.gov.au/statistics/tables/csv/f2.1-data.csv?v=2022-09-08-09-00-18\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}interest_rate/\", \"interest_rate_raw.csv\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013']\n",
      "    time  bond\n",
      "16  2013  2.96\n",
      "28  2014  2.28\n",
      "40  2015  2.10\n",
      "52  2016  1.97\n",
      "64  2017  2.03\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "interest_df = pd.read_csv(f\"{OUTPUT_DIR}interest_rate/interest_rate_raw.csv\")\n",
    "\n",
    "# data cleaning and renaming\n",
    "col_names = [\"time\"] + list(interest_df.iloc[[0]].values[0][1:])\n",
    "interest_df = interest_df.iloc[11:]\n",
    "interest_df.columns = col_names\n",
    "interest_df = interest_df[[\"time\", \"Commonwealth Government 3 year bond\"]]\n",
    "\n",
    "# data selection\n",
    "interest_df.columns = [\"time\", \"bond\"]\n",
    "interest_df = interest_df.loc[interest_df[\"time\"].str.contains(\"Dec\")]\n",
    "digit_re = re.compile(r\"(\\d+)\")\n",
    "print(digit_re.findall(\"Dec-2013\"))\n",
    "\n",
    "interest_df[\"time\"] = interest_df[\"time\"].apply(lambda x: int(digit_re.findall(x)[0]))\n",
    "\n",
    "print(interest_df.head())\n",
    "\n",
    "\n",
    "# interest_sdf = spark.read.csv(f\"{OUTPUT_DIR}interest_rate/interest_rate_raw.csv\")\n",
    "# print(\"Before selection:\")\n",
    "# interest_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# # feature selection / rename / reset datatype\n",
    "# interest_sdf = interest_sdf[[\"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "# interest_sdf = (\n",
    "#     interest_sdf.withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "#     .withColumnRenamed(\"OBS_VALUE\", \"price_index\")\n",
    "#     .withColumn(\"price_index\", F.col(\"price_index\").cast(\"int\"))\n",
    "# )\n",
    "# interest_sdf = interest_sdf.filter(F.col(\"year\").contains(\"Q4\"))\n",
    "# interest_sdf = interest_sdf.withColumn(\"year\", F.substring(\"year\", 1, 4).cast(\"int\"))\n",
    "\n",
    "# # # Filter: victoria SA2\n",
    "# # vic_df = pd.read_csv(f\"{OUTPUT_DIR}SA2_TO_Name.csv\")\n",
    "# # vic_sa2 = vic_df[\"code\"].tolist()\n",
    "# # interest_sdf = interest_sdf.filter(F.col(\"SA2\").isin(vic_sa2))\n",
    "\n",
    "# # save file\n",
    "# print(\"After selection:\")\n",
    "# interest_sdf.show(2, vertical=True, truncate=100)\n",
    "# interest_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(f\"{OUTPUT_DIR}interest_rate/interest_rate.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Household income (weekly) (exclude visitor/non-classifiable) (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved: ../data/raw/Prediction/Household_income_group/Household_income_match.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### pull household income data\n",
    "url = f\"https://api.data.abs.gov.au/data/ABS,C21_G33_SA2,1.0.0/...SA2.?\\\n",
    "startPeriod=2021&dimensionAtObservation=AllDimensions\"\n",
    "response = requests.get(url, headers=headers)\n",
    "write_file(f\"{OUTPUT_DIR}Household_income_group/\", \"Household_income_raw.csv\",\n",
    "            response.text)\n",
    "\n",
    "### pull match data\n",
    "match_url = \"https://api.data.abs.gov.au/datastructure/ABS/C21_G33_SA2/1.\\\n",
    "0.0?references=all\"\n",
    "match_output_dir = f\"{OUTPUT_DIR}Household_income_group/\"\n",
    "match_file_name = \"Household_income_match\"\n",
    "get_match_list(match_url, match_output_dir, match_file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before selection:\n",
      "-RECORD 0-----------------------------\n",
      " DATAFLOW    | ABS:C21_G33_SA2(1.0.0) \n",
      " HIND        | 7                      \n",
      " HHCD        | 1_2                    \n",
      " REGION      | 101021008              \n",
      " REGION_TYPE | SA2                    \n",
      " STATE       | 1                      \n",
      " TIME_PERIOD | 2021                   \n",
      " OBS_VALUE   | 94                     \n",
      "-RECORD 1-----------------------------\n",
      " DATAFLOW    | ABS:C21_G33_SA2(1.0.0) \n",
      " HIND        | 7                      \n",
      " HHCD        | _T                     \n",
      " REGION      | 101021611              \n",
      " REGION_TYPE | SA2                    \n",
      " STATE       | 1                      \n",
      " TIME_PERIOD | 2021                   \n",
      " OBS_VALUE   | 124                    \n",
      "only showing top 2 rows\n",
      "\n",
      "After selection:\n",
      "-RECORD 0---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "-RECORD 1---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "income_sdf = spark.read.csv(\n",
    "    f\"{OUTPUT_DIR}Household_income_group/Household_income_raw.csv\", header=True\n",
    ")\n",
    "print(\"Before selection:\")\n",
    "income_sdf.show(2, vertical=True, truncate=100)\n",
    "\n",
    "# feature selection / rename / reset datatype\n",
    "income_sdf = income_sdf[[\"REGION\", \"HIND\", \"HHCD\", \"OBS_VALUE\", \"STATE\", \"TIME_PERIOD\"]]\n",
    "income_sdf = (\n",
    "    income_sdf.withColumnRenamed(\"REGION\", \"SA2\")\n",
    "    .withColumn(\"SA2\", F.col(\"SA2\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"TIME_PERIOD\", \"year\")\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"OBS_VALUE\", \"popultaion\")\n",
    "    .withColumn(\"popultaion\", F.col(\"popultaion\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"STATE\", \"state\")\n",
    "    .withColumn(\"state\", F.col(\"state\").cast(\"int\"))\n",
    "    .withColumnRenamed(\"HIND\", \"income_level\")\n",
    "    .withColumnRenamed(\"HHCD\", \"household_type\")\n",
    ")\n",
    "match_sdf = spark.read.csv(\n",
    "    f\"{OUTPUT_DIR}Household_income_group/Household_income_match.csv\", header=True\n",
    ")[[\"id\", \"Name\"]].withColumnRenamed(\"id\", \"code\")\n",
    "\n",
    "# Filter: victoria\n",
    "income_sdf = income_sdf.filter(F.col(\"state\") == 2)\n",
    "income_sdf = income_sdf[[\"SA2\", \"year\", \"household_type\", \"income_level\",\\\n",
    "                        \"popultaion\"]]\n",
    "\n",
    "\n",
    "# inner join\n",
    "match_sdf.createOrReplaceTempView(\"match\")\n",
    "income_sdf.createOrReplaceTempView(\"income_sdf\")\n",
    "matched_sdf = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT SA2, year, Name AS household_type, income_level, popultaion\n",
    "    FROM(\n",
    "        SELECT SA2, year, household_type, Name AS income_level, popultaion\n",
    "        FROM income_sdf\n",
    "        INNER JOIN match ON income_sdf.income_level = match.code) AS half\n",
    "    INNER JOIN match ON half.household_type = match.code\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# write filtered file\n",
    "print(\"After selection:\")\n",
    "matched_sdf.show(2, vertical=True, truncate=100)\n",
    "matched_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}Household_income_group/Household_income.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing:\n",
      "-RECORD 0---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "-RECORD 1---------------------------\n",
      " SA2            | 201011002         \n",
      " year           | 2021              \n",
      " household_type | Family households \n",
      " income_level   | Total             \n",
      " popultaion     | 3032              \n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "match_table: \n",
      "-RECORD 0-----------------\n",
      " income_level | $1-$149   \n",
      " lower_bound  | $1        \n",
      "-RECORD 1-----------------\n",
      " income_level | $500-$649 \n",
      " lower_bound  | $500      \n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "after processing:\n",
      "-RECORD 0----------------\n",
      " SA2         | 204011056 \n",
      " year        | 2021      \n",
      " lower_bound | $1        \n",
      " popultaion  | 31        \n",
      "-RECORD 1----------------\n",
      " SA2         | 204011056 \n",
      " year        | 2021      \n",
      " lower_bound | $1        \n",
      " popultaion  | 31        \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "household_sdf = spark.read.csv(f\"{OUTPUT_DIR}Household_income_group/Household_income.csv\", header=True)\n",
    "print(\"before processing:\")\n",
    "household_sdf.show(2, vertical = True, truncate=100)\n",
    "\n",
    "# filte household_type\n",
    "household_sdf = household_sdf.filter(F.col(\"household_type\") == \"Total\")\n",
    "\n",
    "# filte income_level and find lower bound of each income_level\n",
    "income_values = household_sdf.select(F.col('income_level'))\\\n",
    "                            .distinct().select(\"income_level\")\\\n",
    "                            .rdd.flatMap(lambda x: x).collect()\n",
    "digital_re = re.compile(r'[0-9\\,]+')\n",
    "int_re = re.compile(r'\\d+')\n",
    "income_list = []\n",
    "income_lb = []\n",
    "for income_value in income_values:\n",
    "    result = digital_re.findall(income_value)\n",
    "    if result:\n",
    "        income_list.append(income_value)\n",
    "        income_lb.append((income_value, \"$\"+''.join(int_re.findall(result[0]))))\n",
    "household_sdf = household_sdf.filter(F.col(\"income_level\").isin(income_list))\n",
    "\n",
    "\n",
    "# change full boundary to lower boundary\n",
    "match_sdf = spark.createDataFrame(income_lb, [\"income_level\", \"lower_bound\"])\n",
    "print(\"\\nmatch_table: \")\n",
    "match_sdf.show(2, vertical = True, truncate=100)\n",
    "household_sdf.createOrReplaceTempView(\"household\")\n",
    "match_sdf.createOrReplaceTempView(\"match\")\n",
    "household_sdf = spark.sql(\"\"\"\n",
    "    SELECT SA2, year, lower_bound, popultaion\n",
    "    FROM household\n",
    "    INNER JOIN match ON household.income_level = match.income_level\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nafter processing:\")\n",
    "household_sdf.show(2, vertical = True, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
