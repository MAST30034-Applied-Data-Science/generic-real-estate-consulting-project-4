{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERP + household + school_count + PTV + median_rent-> by sa2\n",
    "##### INPUT:\n",
    "School location\n",
    "- ../data/raw/ACARA/School_location/School_location.csv\n",
    "- School Name (String), SA2 (int), Latitude (float), Longitude (float), School Type (String)\n",
    "\n",
    "ERP\n",
    "- ../data/raw/ABS/ERP/ERP.csv\n",
    "- SA2 (int), year (int), population (int)\n",
    "\n",
    "Median household income (weekly) (2021) (By SA2)\n",
    "- ../data/raw/ABS/Household_income/Household_income.csv\n",
    "- SA2 (int), year (int),  household_type (String), income_level (String), popultaion (int)\n",
    "\n",
    "School location\n",
    "- ../data/raw/ACARA/School_location/School_location.csv\n",
    "- School Name (String), SA2 (int), Latitude (float), Longitude (float), School Type (String)\n",
    "\n",
    "Median rent\n",
    "- ../data/raw/DHHS/history_rent.csv\n",
    "- SA2 (int), year (int), month (int), count (int), median (float)\n",
    "##### OUTPUT:\n",
    "SA2_info\n",
    "- ../data/curated/sa2_info.csv\n",
    "- SA2 (int), school_count (int), ERP_population (int), median_income (float), metrobus_count (int), metrotrain_count (int), metrotram_count (int), regbus_count (int), regcoach_count (int), regtrain_count (int), skybus_count (int), recr_count (int), comm_count (int), \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ERP + price_index + interest_rate -> year, SA2\n",
    "- median rent\n",
    "##### INPUT:\n",
    "ERP\n",
    "- ../data/raw/ABS/ERP/ERP.csv\n",
    "- SA2 (int), year (int), population (int)\n",
    "\n",
    "Residential Property Price Index (1/2011 - 12/2021) (AUS)\n",
    "- ../data/raw/ABS/Price_index/Price_index.csv\n",
    "- year (int), price_index (int)\n",
    "\n",
    "Interest rate (2013 - 2021) (AUS)\n",
    "- ../data/raw/rba/interest_rate/interest_rate.csv\n",
    "- time(int, year), bond (float, risk free interest rate)\n",
    "\n",
    "Median rent\n",
    "- ../data/raw/DHHS/history_rent.csv\n",
    "- SA2 (int), year (int), month (int), count (int), median (float)\n",
    "\n",
    "##### OUTPUT:\n",
    "history_info\n",
    "- ../data/curated/history_info.csv\n",
    "- SA2 (int), year (int), population (int), bond (float), price_index (int), \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SA2(ERP + household + school_count + PTV + FOI) + rent(basic + distance) -> rent_price\n",
    "##### INPUT:\n",
    "SA2:\n",
    "- ALL: ../data/curated/sa2_info.csv\n",
    "\n",
    "rent information with distance\n",
    "- ../data/curated/rent_distance.csv\n",
    "- rent_index (int), SA2 (int), rent (float), bedroom (int), baths (int), parking (int), Latitude (float), Longitude (float), school_dis (float), station_dis (float)\n",
    "\n",
    "##### OUTPUT:\n",
    "- ../data/curated/rent_info.csv\n",
    "- rent (float), bedroom (int), baths (int), parking (int), school_dis (float), station_dis (float), SA2 (int), school_count (int), ERP_population (int), median_income (float), metrobus_count (int), metrotrain_count (int), metrotram_count (int), regbus_count (int), regcoach_count (int), regtrain_count (int), skybus_count (int), recr_count (int), comm_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Assignment_2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "headers = {\"accept\": \"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def gpd_station_merge(poly_gdf, file_path, by_id_name = \"SA2_CODE21\",\\\n",
    "    station_id_name = \"STOP_ID\", method={\"STOP_ID\": \"count\"}):\n",
    "    \"\"\"\n",
    "        A function used to merge shape file in path: {file_path} to a \n",
    "        geopandas dataframe {poly_gdf} with POLYGON geometry. \n",
    "        poly_gdf: a geopandas.GeoDataFrame object contains POLYGON geometry\n",
    "        file_path: a String of file path to read target shape file\n",
    "        by_id_name: a String of id name to perform groupby option\n",
    "        station_id_name: a String of id name stated in the readed gdf\n",
    "        method: a Dict of operations to perform after groupby\n",
    "    \"\"\"\n",
    "\n",
    "    ### read station file\n",
    "    station_gdf = gpd.read_file(file_path)\n",
    "\n",
    "    # metro bus station feature selection\n",
    "    station_gdf = station_gdf[[station_id_name, \"geometry\"]]\n",
    "    \n",
    "\n",
    "\n",
    "    # merge tabels\n",
    "    join_gdf = gpd.sjoin(poly_gdf, station_gdf, how=\"left\")\n",
    "    join_gdf = join_gdf.groupby(by_id_name).agg(method)\n",
    "    \n",
    "    return join_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA2_info\n",
    "#### ERP + household + school_count + PTV + median_rent-> by sa2\n",
    "Read and prepare all data sets and create TempView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------\n",
      " SA2          | 209031212 \n",
      " school_count | 9         \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2021      \n",
      " population | 9656      \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------\n",
      " SA2           | 213051589 \n",
      " median_income | 1862      \n",
      "-RECORD 1------------------\n",
      " SA2           | 209041437 \n",
      " median_income | 1979      \n",
      "only showing top 2 rows\n",
      "\n",
      "-RECORD 0----------------------------------------------------------------------------------------------------------------\n",
      " SA2_CODE21       | 201011001                                                                                            \n",
      " geometry         | POLYGON ((143.78282104711133 -37.566657808073295, 143.75557764214773 -37.56346721632544, 143.7480... \n",
      " metrobus_count   | 0                                                                                                    \n",
      " metrotrain_count | 0                                                                                                    \n",
      " metrotram_count  | 0                                                                                                    \n",
      " regbus_count     | 43                                                                                                   \n",
      " regcoach_count   | 0                                                                                                    \n",
      " regtrain_count   | 0                                                                                                    \n",
      " skybus_count     | 0                                                                                                    \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0---------------\n",
      " SA2        | 201011001 \n",
      " recr_count | 0         \n",
      " comm_count | 0         \n",
      "only showing top 1 row\n",
      "\n",
      "22/09/19 00:21:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , SA2, year, month, count, median\n",
      " Schema: _c0, SA2, year, month, count, median\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/raw/DHHS/history_rent.csv\n",
      "-RECORD 0-----------\n",
      " _c0    | 87        \n",
      " SA2    | 201011001 \n",
      " year   | 2021      \n",
      " month  | 3         \n",
      " count  | 502       \n",
      " median | 387.5     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read school file\n",
    "school_sdf = spark.read.csv(f\"../data/raw/ACARA/School_location/School_location.csv\", header=True)\n",
    "\n",
    "# count school by SA2\n",
    "school_count = school_sdf.groupBy(\"SA2\").agg({\n",
    "    \"School Name\": \"count\"\n",
    "})\n",
    "school_count = school_count.withColumnRenamed( \"count(School Name)\", \"school_count\")\n",
    "school_count.show(1, vertical = True, truncate=100)\n",
    "school_count.createOrReplaceTempView(\"school\")\n",
    "\n",
    "\n",
    "\n",
    "# read ERP file and create tempview\n",
    "ERP_sdf = spark.read.csv(f\"../data/raw/ABS/ERP/ERP.csv\", header=True)\n",
    "ERP_sdf = ERP_sdf.filter(F.col(\"year\") == 2021)\n",
    "ERP_sdf.show(1, vertical = True, truncate=100)\n",
    "ERP_sdf.createOrReplaceTempView(\"ERP\")\n",
    "\n",
    "\n",
    "\n",
    "# read median household income file and create tempview\n",
    "household_sdf = spark.read.csv(f\"../data/raw/ABS/Household_income/Household_income.csv\", header=True)\n",
    "household_sdf.show(2, vertical = True, truncate=100)\n",
    "household_sdf.createOrReplaceTempView(\"household\")\n",
    "\n",
    "\n",
    "\n",
    "# read PTV station file and create tempview\n",
    "ptv_sdf = spark.read.csv(f\"../data/raw/PTV/public_trans.csv\", header=True)\n",
    "ptv_sdf.show(1, vertical = True, truncate=100)\n",
    "ptv_sdf.createOrReplaceTempView(\"ptv\")\n",
    "\n",
    "\n",
    "\n",
    "# read PTV station file and create tempview\n",
    "foi_Sdf = spark.read.csv(f\"../data/raw/FOI/foi_count_by_sa2.csv\", header=True)\n",
    "foi_Sdf.show(1, vertical = True, truncate=100)\n",
    "foi_Sdf.createOrReplaceTempView(\"foi\")\n",
    "\n",
    "\n",
    "\n",
    "# read median rent file and create tempview\n",
    "mrent_sdf = spark.read.csv(f\"../data/raw/DHHS/history_rent.csv\", header=True).dropna()\n",
    "mrent_sdf = mrent_sdf.filter((F.col(\"year\") == 2021) & (F.col(\"month\") == 3))\n",
    "mrent_sdf.show(1, vertical = True, truncate=100)\n",
    "mrent_sdf.createOrReplaceTempView(\"mrent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA2', 'school_count']\n",
      "['SA2', 'year', 'population']\n",
      "['SA2', 'median_income']\n",
      "['SA2_CODE21', 'geometry', 'metrobus_count', 'metrotrain_count', 'metrotram_count', 'regbus_count', 'regcoach_count', 'regtrain_count', 'skybus_count']\n",
      "['SA2', 'recr_count', 'comm_count']\n",
      "['_c0', 'SA2', 'year', 'month', 'count', 'median']\n",
      "22/09/19 00:21:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , SA2, year, month, count, median\n",
      " Schema: _c0, SA2, year, month, count, median\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/raw/DHHS/history_rent.csv\n",
      "-RECORD 0---------------------\n",
      " SA2              | 202011018 \n",
      " school_count     | 13        \n",
      " ERP_population   | 14951     \n",
      " median_income    | 1267      \n",
      " metrobus_count   | 0         \n",
      " metrotrain_count | 0         \n",
      " metrotram_count  | 0         \n",
      " regbus_count     | 142       \n",
      " regcoach_count   | 2         \n",
      " regtrain_count   | 1         \n",
      " skybus_count     | 0         \n",
      " recr_count       | 1         \n",
      " comm_count       | 1         \n",
      " deal_count       | 739       \n",
      " median_rent      | 350.0     \n",
      "only showing top 1 row\n",
      "\n",
      "['SA2', 'school_count', 'ERP_population', 'median_income', 'metrobus_count', 'metrotrain_count', 'metrotram_count', 'regbus_count', 'regcoach_count', 'regtrain_count', 'skybus_count', 'recr_count', 'comm_count', 'deal_count', 'median_rent']\n",
      "22/09/19 00:21:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , SA2, year, month, count, median\n",
      " Schema: _c0, SA2, year, month, count, median\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/raw/DHHS/history_rent.csv\n"
     ]
    }
   ],
   "source": [
    "# inner join\n",
    "print(school_count.columns)\n",
    "print(ERP_sdf.columns)\n",
    "print(household_sdf.columns)\n",
    "print(ptv_sdf.columns)\n",
    "print(foi_Sdf.columns)\n",
    "print(mrent_sdf.columns)\n",
    "combine_sdf = spark.sql(\"\"\"\n",
    "    SELECT  school.SA2, school.school_count, \n",
    "        ERP.population AS ERP_population, median_income, \n",
    "        metrobus_count, metrotrain_count, metrotram_count, \n",
    "        regbus_count, regcoach_count, regtrain_count, skybus_count,\n",
    "        recr_count, comm_count, mrent.count AS deal_count,\n",
    "        mrent.median AS median_rent\n",
    "    FROM school\n",
    "    INNER JOIN ERP ON school.SA2 = ERP.SA2\n",
    "    INNER JOIN household ON school.SA2 = household.SA2\n",
    "    INNER JOIN ptv ON school.SA2 = ptv.SA2_CODE21\n",
    "    INNER JOIN foi ON school.SA2 = foi.SA2\n",
    "    INNER JOIN mrent ON school.SA2 = mrent.SA2\n",
    "\"\"\")\n",
    "combine_sdf.show(1, vertical = True, truncate=100)\n",
    "print(combine_sdf.columns)\n",
    "combine_sdf.toPandas().to_csv(\n",
    "    f\"../data/curated/sa2_info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history_info\n",
    "\n",
    "#### ERP + interest_rate + price_index -> year, SA2\n",
    "\n",
    "Read and prepare all data sets and create TempView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2021      \n",
      " population | 9656      \n",
      "only showing top 1 row\n",
      "\n",
      "22/09/18 23:22:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , year, bond\n",
      " Schema: _c0, year, bond\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/raw/rba/interest_rate/interest_rate.csv\n",
      "-RECORD 0----\n",
      " _c0  | 112  \n",
      " year | 2021 \n",
      " bond | 0.93 \n",
      "\n",
      "-RECORD 0-----------\n",
      " year        | 2021 \n",
      " price_index | 185  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ERP file and create tempview\n",
    "ERP_sdf = spark.read.csv(f\"../data/raw/ABS/ERP/ERP.csv\", header=True)\n",
    "ERP_sdf = ERP_sdf.filter(F.col(\"year\") == 2021)\n",
    "ERP_sdf.show(1, vertical = True, truncate=100)\n",
    "ERP_sdf.createOrReplaceTempView(\"ERP\")\n",
    "\n",
    "# read population projection file and create tempview\n",
    "interest_sdf = spark.read.csv(f\"../data/raw/rba/interest_rate/interest_rate.csv\", header=True)\n",
    "interest_sdf = interest_sdf.filter(F.col(\"year\") == 2021)\n",
    "interest_sdf.show(1, vertical = True, truncate=100)\n",
    "interest_sdf.createOrReplaceTempView(\"interest\")\n",
    "\n",
    "# read property price index file and create tempview\n",
    "index_sdf = spark.read.csv(f\"../data/raw/ABS/Price_index/Price_index.csv\", header=True)\n",
    "index_sdf = index_sdf.filter(F.col(\"year\") == 2021)\n",
    "index_sdf.show(1, vertical = True, truncate=100)\n",
    "index_sdf.createOrReplaceTempView(\"index\")\n",
    "\n",
    "\n",
    "# # read median property rent file and create tempview\n",
    "# mrent_sdf = spark.read.csv(f\"../data/raw/DHHS/history_rent.csv\", header=True)\n",
    "# mrent_sdf = mrent_sdf.filter(F.col(\"year\") == 2021)\n",
    "# mrent_sdf.show(1, vertical = True, truncate=100)\n",
    "# mrent_sdf.createOrReplaceTempView(\"mrent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA2', 'year', 'population']\n",
      "['_c0', 'year', 'bond']\n",
      "['year', 'price_index']\n",
      "['_c0', 'SA2', 'year', 'month', 'count', 'median']\n",
      "-RECORD 0----------------\n",
      " SA2         | 201011481 \n",
      " year        | 2021      \n",
      " population  | 9656      \n",
      " bond        | 0.93      \n",
      " price_index | 185       \n",
      "only showing top 1 row\n",
      "\n",
      "['SA2', 'year', 'population', 'bond', 'price_index']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# inner join\n",
    "print(ERP_sdf.columns)\n",
    "print(interest_sdf.columns)\n",
    "print(index_sdf.columns)\n",
    "print(mrent_sdf.columns)\n",
    "combine_sdf = spark.sql(\"\"\"\n",
    "    SELECT  ERP.SA2, ERP.year, population, bond, price_index\n",
    "    FROM ERP\n",
    "    INNER JOIN interest ON ERP.year = interest.year\n",
    "    INNER JOIN index ON ERP.year = index.year\n",
    "\"\"\")\n",
    "combine_sdf.show(1, vertical = True, truncate=100)\n",
    "print(combine_sdf.columns)\n",
    "combine_sdf.toPandas().to_csv(\n",
    "    f\"../data/curated/history_info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rent_info\n",
    "- SA2(ERP + household + school_count + PTV + FOI) + rent(basic + distance) -> rent_price\n",
    "- ../data/curated/rent_info.csv\n",
    "- rent (float), bedroom (int), baths (int), parking (int), school_dis (float), station_dis (float), SA2 (int), school_count (int), ERP_population (int), median_income (float), metrobus_count (int), metrotrain_count (int), metrotram_count (int), regbus_count (int), regcoach_count (int), regtrain_count (int), skybus_count (int), recr_count (int), comm_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/18 23:22:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , SA2, school_count, ERP_population, median_income, metrobus_count, metrotrain_count, metrotram_count, regbus_count, regcoach_count, regtrain_count, skybus_count, recr_count, comm_count\n",
      " Schema: _c0, SA2, school_count, ERP_population, median_income, metrobus_count, metrotrain_count, metrotram_count, regbus_count, regcoach_count, regtrain_count, skybus_count, recr_count, comm_count\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/curated/sa2_info.csv\n",
      "-RECORD 0---------------------\n",
      " _c0              | 0         \n",
      " SA2              | 202011018 \n",
      " school_count     | 13        \n",
      " ERP_population   | 14951     \n",
      " median_income    | 1267      \n",
      " metrobus_count   | 0         \n",
      " metrotrain_count | 0         \n",
      " metrotram_count  | 0         \n",
      " regbus_count     | 142       \n",
      " regcoach_count   | 2         \n",
      " regtrain_count   | 1         \n",
      " skybus_count     | 0         \n",
      " recr_count       | 1         \n",
      " comm_count       | 1         \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------\n",
      " rent_index  | 0           \n",
      " SA2         | 201011001   \n",
      " rent        | 490.0       \n",
      " bedroom     | 4           \n",
      " baths       | 2           \n",
      " parking     | 2           \n",
      " Latitude    | -37.5630731 \n",
      " Longitude   | 143.7938749 \n",
      " school_dis  | 1651.7      \n",
      " station_dis | 5895.5      \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read SA2 file and create tempview\n",
    "SA2_sdf = spark.read.csv(f\"../data/curated/sa2_info.csv\", header=True)\n",
    "SA2_sdf.show(1, vertical = True, truncate=100)\n",
    "SA2_sdf.createOrReplaceTempView(\"SA2\")\n",
    "\n",
    "# read rent data file and create tempview\n",
    "rent_sdf = spark.read.csv(f\"../data/curated/rent_distance.csv\", header=True)\n",
    "rent_sdf.show(1, vertical = True, truncate=100)\n",
    "rent_sdf.createOrReplaceTempView(\"rent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'SA2', 'school_count', 'ERP_population', 'median_income', 'metrobus_count', 'metrotrain_count', 'metrotram_count', 'regbus_count', 'regcoach_count', 'regtrain_count', 'skybus_count', 'recr_count', 'comm_count']\n",
      "['rent_index', 'SA2', 'rent', 'bedroom', 'baths', 'parking', 'Latitude', 'Longitude', 'school_dis', 'station_dis']\n",
      "-RECORD 0---------------------\n",
      " rent             | 490.0     \n",
      " bedroom          | 4         \n",
      " baths            | 2         \n",
      " parking          | 2         \n",
      " school_dis       | 1651.7    \n",
      " station_dis      | 5895.5    \n",
      " SA2              | 201011001 \n",
      " school_count     | 4         \n",
      " ERP_population   | 16823     \n",
      " median_income    | 1952      \n",
      " metrobus_count   | 0         \n",
      " metrotrain_count | 0         \n",
      " metrotram_count  | 0         \n",
      " regbus_count     | 43        \n",
      " regcoach_count   | 0         \n",
      " regtrain_count   | 0         \n",
      " skybus_count     | 0         \n",
      " recr_count       | 0         \n",
      " comm_count       | 0         \n",
      "only showing top 1 row\n",
      "\n",
      "['rent', 'bedroom', 'baths', 'parking', 'school_dis', 'station_dis', 'SA2', 'school_count', 'ERP_population', 'median_income', 'metrobus_count', 'metrotrain_count', 'metrotram_count', 'regbus_count', 'regcoach_count', 'regtrain_count', 'skybus_count', 'recr_count', 'comm_count']\n"
     ]
    }
   ],
   "source": [
    "# inner join\n",
    "print(SA2_sdf.columns)\n",
    "print(rent_sdf.columns)\n",
    "combine_sdf = spark.sql(\"\"\"\n",
    "    SELECT  rent, bedroom, baths, parking, school_dis, station_dis, rent.SA2,\n",
    "        school_count, ERP_population, median_income, metrobus_count, \n",
    "        metrotrain_count, metrotram_count, regbus_count, regcoach_count,\n",
    "        regtrain_count, skybus_count, recr_count, comm_count\n",
    "    FROM SA2\n",
    "    INNER JOIN rent ON SA2.SA2 = rent.SA2\n",
    "\"\"\")\n",
    "combine_sdf.show(1, vertical = True, truncate=100)\n",
    "print(combine_sdf.columns)\n",
    "combine_sdf.toPandas().to_csv(\n",
    "    f\"../data/curated/rent_info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Junhua Liu for study use only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
