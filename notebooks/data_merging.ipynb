{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final outputs:\n",
    "\n",
    "ERP + household + school_count + PTV -> by sa2\n",
    "SA2_info\n",
    "\n",
    "ERP + price_index + interest_rate + price_index -> year, SA2\n",
    "history_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Assignment_2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "INPUT_DIR = \"../data/raw/\"\n",
    "OUTPUT_DIR = \"../data/curated/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA2_info\n",
    "#### ERP + household + school_count + PTV -> by sa2\n",
    "Read and prepare all data sets and create TempView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------\n",
      " SA2          | 209031212 \n",
      " school_count | 9         \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2021      \n",
      " population | 9656      \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------\n",
      " SA2           | 213051589 \n",
      " median_income | 1862      \n",
      "-RECORD 1------------------\n",
      " SA2           | 209041437 \n",
      " median_income | 1979      \n",
      "only showing top 2 rows\n",
      "\n",
      "-RECORD 0----------------------------------------------------------------------------------------------------------------\n",
      " SA2_CODE21       | 201011001                                                                                            \n",
      " geometry         | POLYGON ((143.78282104711133 -37.566657808073295, 143.75557764214773 -37.56346721632544, 143.7480... \n",
      " metrobus_count   | 0                                                                                                    \n",
      " metrotrain_count | 0                                                                                                    \n",
      " metrotram_count  | 0                                                                                                    \n",
      " regbus_count     | 43                                                                                                   \n",
      " regcoach_count   | 0                                                                                                    \n",
      " regtrain_count   | 0                                                                                                    \n",
      " skybus_count     | 0                                                                                                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read school file\n",
    "school_sdf = spark.read.csv(f\"{INPUT_DIR}ACARA/School_location/School_location.csv\", header=True)\n",
    "\n",
    "# count school by SA2\n",
    "school_count = school_sdf.groupBy(\"SA2\").agg({\n",
    "    \"School Name\": \"count\"\n",
    "})\n",
    "school_count = school_count.withColumnRenamed( \"count(School Name)\", \"school_count\")\n",
    "school_count.show(1, vertical = True, truncate=100)\n",
    "school_count.createOrReplaceTempView(\"school\")\n",
    "\n",
    "\n",
    "\n",
    "# read ERP file and create tempview\n",
    "ERP_sdf = spark.read.csv(f\"{INPUT_DIR}ABS/ERP/ERP.csv\", header=True)\n",
    "ERP_sdf = ERP_sdf.filter(F.col(\"year\") == 2021)\n",
    "ERP_sdf.show(1, vertical = True, truncate=100)\n",
    "ERP_sdf.createOrReplaceTempView(\"ERP\")\n",
    "\n",
    "\n",
    "\n",
    "# read median household income file and create tempview\n",
    "household_sdf = spark.read.csv(f\"{INPUT_DIR}ABS/Household_income/Household_income.csv\", header=True)\n",
    "household_sdf.show(2, vertical = True, truncate=100)\n",
    "household_sdf.createOrReplaceTempView(\"household\")\n",
    "\n",
    "# read PTV station file and create tempview\n",
    "ptv_sdf = spark.read.csv(f\"{INPUT_DIR}PTV/public_trans.csv\", header=True)\n",
    "ptv_sdf.show(1, vertical = True, truncate=100)\n",
    "ptv_sdf.createOrReplaceTempView(\"ptv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA2', 'school_count']\n",
      "['SA2', 'year', 'population']\n",
      "['SA2', 'median_income']\n",
      "-RECORD 0---------------------\n",
      " SA2              | 202011018 \n",
      " school_count     | 13        \n",
      " ERP_population   | 14951     \n",
      " median_income    | 1267      \n",
      " metrobus_count   | 0         \n",
      " metrotrain_count | 0         \n",
      " metrotram_count  | 0         \n",
      " regbus_count     | 142       \n",
      " regcoach_count   | 2         \n",
      " regtrain_count   | 1         \n",
      " skybus_count     | 0         \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inner join\n",
    "print(school_count.columns)\n",
    "print(ERP_sdf.columns)\n",
    "print(household_sdf.columns)\n",
    "combine_sdf = spark.sql(\"\"\"\n",
    "    SELECT  school.SA2, school.school_count, \n",
    "        ERP.population AS ERP_population, median_income, \n",
    "        metrobus_count, metrotrain_count, metrotram_count, \n",
    "        regbus_count, regcoach_count, regtrain_count, skybus_count\n",
    "    FROM school\n",
    "    INNER JOIN ERP ON school.SA2 = ERP.SA2\n",
    "    INNER JOIN household ON school.SA2 = household.SA2\n",
    "    INNER JOIN ptv ON school.SA2 = ptv.SA2_CODE21\n",
    "\"\"\")\n",
    "combine_sdf.show(1, vertical = True, truncate=100)\n",
    "combine_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}sa2_info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history_data\n",
    "\n",
    "#### ERP + interest_rate + price_index -> year, SA2\n",
    "\n",
    "Read and prepare all data sets and create TempView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " SA2        | 201011481 \n",
      " year       | 2021      \n",
      " population | 9656      \n",
      "only showing top 1 row\n",
      "\n",
      "22/09/12 22:48:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , year, bond\n",
      " Schema: _c0, year, bond\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/bruce/projects/ass2/data/raw/rba/interest_rate/interest_rate.csv\n",
      "-RECORD 0----\n",
      " _c0  | 112  \n",
      " year | 2021 \n",
      " bond | 0.93 \n",
      "\n",
      "-RECORD 0-----------\n",
      " year        | 2021 \n",
      " price_index | 185  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ERP file and create tempview\n",
    "ERP_sdf = spark.read.csv(f\"{INPUT_DIR}ABS/ERP/ERP.csv\", header=True)\n",
    "ERP_sdf = ERP_sdf.filter(F.col(\"year\") == 2021)\n",
    "ERP_sdf.show(1, vertical = True, truncate=100)\n",
    "ERP_sdf.createOrReplaceTempView(\"ERP\")\n",
    "\n",
    "# read population projection file and create tempview\n",
    "interest_sdf = spark.read.csv(f\"{INPUT_DIR}rba/interest_rate/interest_rate.csv\", header=True)\n",
    "interest_sdf = interest_sdf.filter(F.col(\"year\") == 2021)\n",
    "interest_sdf.show(1, vertical = True, truncate=100)\n",
    "interest_sdf.createOrReplaceTempView(\"interest\")\n",
    "\n",
    "# read property price index file and create tempview\n",
    "index_sdf = spark.read.csv(f\"{INPUT_DIR}ABS/Price_index/Price_index.csv\", header=True)\n",
    "index_sdf = index_sdf.filter(F.col(\"year\") == 2021)\n",
    "index_sdf.show(1, vertical = True, truncate=100)\n",
    "index_sdf.createOrReplaceTempView(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA2', 'year', 'population']\n",
      "['_c0', 'year', 'bond']\n",
      "['year', 'price_index']\n",
      "-RECORD 0----------------\n",
      " SA2         | 201011481 \n",
      " year        | 2021      \n",
      " population  | 9656      \n",
      " bond        | 0.93      \n",
      " price_index | 185       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# inner join\n",
    "print(ERP_sdf.columns)\n",
    "print(interest_sdf.columns)\n",
    "print(index_sdf.columns)\n",
    "combine_sdf = spark.sql(\"\"\"\n",
    "    SELECT  SA2, ERP.year, population, bond, price_index\n",
    "    FROM ERP\n",
    "    INNER JOIN interest ON ERP.year = interest.year\n",
    "    INNER JOIN index ON ERP.year = index.year\n",
    "\"\"\")\n",
    "combine_sdf.show(1, vertical = True, truncate=100)\n",
    "combine_sdf.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}history_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match SA2 to Rental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
